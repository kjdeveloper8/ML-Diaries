{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdbc0a2a-8b43-45b3-a439-1458831f3fa2",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6272dd76-2c29-478c-b47b-d7145f35209b",
   "metadata": {},
   "source": [
    "#### Simple nn with gradient checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875601bb-ef29-492b-9f00-e9668a8ba76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.checkpoint import checkpoint_sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d35ccf5-f838-4cb1-805a-aa977e036609",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(500, 100) # (in_feature, out_feature)\n",
    "        self.layer2 = nn.Linear(400, 80)\n",
    "        self.layer3 = nn.Linear(300, 60)\n",
    "        self.layer4 = nn.Linear(200, 40)\n",
    "\n",
    "        def forward(self, x):\n",
    "            layers = torch.nn.Sequential(\n",
    "                self.layer1,\n",
    "                nn.ReLU(),\n",
    "                self.layer2,\n",
    "                nn.ReLU(),\n",
    "                self.layer3,\n",
    "                nn.ReLU(),\n",
    "                self.layer4\n",
    "            )\n",
    "            x = checkpoint_sequential(layers, segments=2, input=x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4dc52a9-79c8-42a1-b452-fc4bd180147c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNN(\n",
       "  (layer1): Linear(in_features=500, out_features=100, bias=True)\n",
       "  (layer2): Linear(in_features=400, out_features=80, bias=True)\n",
       "  (layer3): Linear(in_features=300, out_features=60, bias=True)\n",
       "  (layer4): Linear(in_features=200, out_features=40, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_model = SimpleNN()\n",
    "g_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c840b6-338d-40d8-8479-7d3cf7724444",
   "metadata": {},
   "source": [
    "#### Dropout\n",
    "\n",
    "- To zeroed out neurons randomly to regularize the nn during **training**\n",
    "- Uses bernoulli distribution $1/(1-p)$ -- p is dropout probability\n",
    "- It scales remaining active inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "116e32ec-595e-4fb5-8de4-2a3bb1ec1312",
   "metadata": {},
   "outputs": [],
   "source": [
    "droupout_layer = nn.Dropout(0.4) # p = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c30389af-9ec7-4173-9f5e-d6b99c64e781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dropout(p=0.4, inplace=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "droupout_layer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36c52d05-6e39-4d8d-ad08-3d153a5b6156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5444, 0.4021, 0.1602, 0.3788, 0.5806, 0.2136]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample input\n",
    "d = torch.rand((1,6))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3492f398-617e-4b1c-adc1-56d8418043a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9073, 0.6702, 0.2670, 0.6314, 0.9676, 0.0000]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "droupout_layer(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a7136a7-e9fa-40d6-99e7-bc51ed3bcede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9073, 0.6702, 0.2670, 0.6314, 0.9676, 0.3560]])\n"
     ]
    }
   ],
   "source": [
    "p = 0.4\n",
    "print(d/(1-p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f94854e-c38e-448e-ab2a-9eb36871187a",
   "metadata": {},
   "source": [
    "- Here last value zeroed out (0.2136 -> 0.00) while others incresed as they scaled out :: same as d/(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31699a97-eeb4-4fab-ace0-c82823baabcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dropout(p=0.4, inplace=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eval\n",
    "droupout_layer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae037498-289f-4f52-b111-1b5481ff5e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5444, 0.4021, 0.1602, 0.3788, 0.5806, 0.2136]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9a6621a-38eb-4dec-88a1-2a898ab212dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5444, 0.4021, 0.1602, 0.3788, 0.5806, 0.2136]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "droupout_layer(d) #  No change in value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017b003-5c72-4b95-b6d5-415262e5d685",
   "metadata": {},
   "source": [
    "> Dropuout in NN\n",
    "  <pre>\n",
    "      For p = 0.4 (40% probability)\n",
    "      training: 40% neurons zeroed out so got 60% input\n",
    "      evaluation: it got total 100% inputs\n",
    "      So by scaling out other active inputs it basically brings the desired range during training \n",
    "  </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6c206d-c4c8-4539-bfcd-1f785af4ff04",
   "metadata": {},
   "source": [
    "### Learning NN example\n",
    "\n",
    "Learning XOR operation in nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcf80d19-76b5-4967-b0d1-b38d98dec03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b370231e-6135-4202-9ef5-305264953501",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)                         # set seed to make repeatable\n",
    "lr = 0.1\n",
    "index_list = [0, 1, 2, 3]                 # to randomize order\n",
    "\n",
    "x_train = [np.array([1.0, -1.0, -1.0]),   # input\n",
    "           np.array([1.0, -1.0, 1.0]),\n",
    "           np.array([1.0, 1.0, -1.0]),\n",
    "           np.array([1.0, 1.0, 1.0])]\n",
    "y_train = [0.0, 1.0, 1.0, 0.0]             # output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3efce0f6-8d72-4da6-82db-a98627109512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# track neurons weights\n",
    "def neuron_w(input_count):\n",
    "    weights = np.zeros(input_count+1)\n",
    "    for i in range(1, (input_count+1)):\n",
    "        weights[i] = np.random.uniform(-1.0, 1.0)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1685bbf5-17ae-4329-be9d-ccd17ff227bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_w = [neuron_w(2), neuron_w(2), neuron_w(2)]\n",
    "n_y = [0, 0, 0]\n",
    "n_error = [0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4916c04-fa5e-4478-9d1f-bd2c6316562e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.        , 0.10159581, 0.41629565]),\n",
       " array([ 0.        , -0.41819052,  0.02165521]),\n",
       " array([0.        , 0.78589391, 0.79258618])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d627897-f7db-4c85-a1d4-19b2bb0b4fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_learning():\n",
    "    print('Current weights:')\n",
    "    for i, w in enumerate(n_w):\n",
    "        print(f'neuron = {i}, w0 = {w[0]:.4f}, w1 = {w[1]:.4f}, w2 = {w[2]:.4f}')\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb9d1d71-7258-4bed-b1f7-caaed9ea1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(x):\n",
    "    global n_y\n",
    "    n_y[0] = np.tanh(np.dot(n_w[0], x))         # neuron 0\n",
    "    n_y[1] = np.tanh(np.dot(n_w[1], x))         # neuron 1\n",
    "    n2_inputs = np.array([1.0, n_y[0], n_y[1]]) # 1.0 is bias\n",
    "    z2 = np.dot(n_w[2], n2_inputs)\n",
    "    n_y[2] = 1.0 / (1.0 + np.exp(-z2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b267738-eac2-4c66-a303-55d482ac72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(y_truth):\n",
    "    global n_error\n",
    "    error_prime = -(y_truth - n_y[2]) \n",
    "    derivative = n_y[2] * (1.0 - n_y[2]) \n",
    "    n_error[2] = error_prime * derivative\n",
    "    derivative = 1.0 - n_y[0]**2 \n",
    "    n_error[0] = n_w[2][1] * n_error[2] * derivative\n",
    "    derivative = 1.0 - n_y[1]**2 \n",
    "    n_error[1] = n_w[2][2] * n_error[2] * derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb51f066-a007-4ffc-91a8-affede176f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_weights(x):\n",
    "    global n_w\n",
    "    n_w[0] -= (x * lr * n_error[0])\n",
    "    n_w[1] -= (x * lr * n_error[1])\n",
    "    n2_inputs = np.array([1.0, n_y[0], n_y[1]])\n",
    "    n_w[2] -= (n2_inputs * lr * n_error[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f39cb18-59d9-41ce-90e6-2804b68a9754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current weights:\n",
      "neuron = 0, w0 = 0.0075, w1 = 0.0994, w2 = 0.4177\n",
      "neuron = 1, w0 = 0.0040, w1 = -0.4207, w2 = 0.0226\n",
      "neuron = 2, w0 = 0.0066, w1 = 0.7857, w2 = 0.7934\n",
      "--------------------------------------------------\n",
      "Current weights:\n",
      "neuron = 0, w0 = 0.0181, w1 = 0.1099, w2 = 0.4072\n",
      "neuron = 1, w0 = 0.0137, w1 = -0.4110, w2 = 0.0129\n",
      "neuron = 2, w0 = 0.0214, w1 = 0.7812, w2 = 0.7873\n",
      "--------------------------------------------------\n",
      "Current weights:\n",
      "neuron = 0, w0 = 0.0102, w1 = 0.1021, w2 = 0.3994\n",
      "neuron = 1, w0 = 0.0047, w1 = -0.4200, w2 = 0.0040\n",
      "neuron = 2, w0 = 0.0082, w1 = 0.7748, w2 = 0.7921\n",
      "--------------------------------------------------\n",
      "Current weights:\n",
      "neuron = 0, w0 = 0.0027, w1 = 0.1096, w2 = 0.4069\n",
      "neuron = 1, w0 = -0.0035, w1 = -0.4118, w2 = 0.0122\n",
      "neuron = 2, w0 = -0.0041, w1 = 0.7804, w2 = 0.7872\n",
      "--------------------------------------------------\n",
      "x1 = -1.0, x2 = -1.0, y =0.4808216978192937\n",
      "x1 = -1.0, x2 = 1.0, y =0.6308757817853017\n",
      "x1 = 1.0, x2 = -1.0, y =0.367018628023907\n",
      "x1 = 1.0, x2 = 1.0, y =0.5167479979607066\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "all_correct = False\n",
    "while not all_correct: \n",
    "    all_correct = True\n",
    "    np.random.shuffle(index_list) \n",
    "    \n",
    "for i in index_list: \n",
    "    forward_pass(x_train[i])\n",
    "    backward_pass(y_train[i])\n",
    "    adjust_weights(x_train[i])\n",
    "    show_learning() \n",
    "    \n",
    "for i in range(len(x_train)): \n",
    "    forward_pass(x_train[i])\n",
    "    print(f'x1 = {x_train[i][1]}, x2 = {x_train[i][2]}, y ={n_y[2]}')\n",
    "    if(((y_train[i] < 0.5) and (n_y[2] >= 0.5)) or ((y_train[i] >= 0.5) and (n_y[2] < 0.5))):\n",
    "        all_correct = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
